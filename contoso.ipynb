{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ad87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf1bf8",
   "metadata": {},
   "source": [
    "### Import data from local postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ecfd96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contoso Data Loading ---\n",
      "Database connection established successfully.\n",
      "\n",
      "--- Loading Tables into DataFrames ---\n",
      "\n",
      "Processing table: 'currencyexchange'\n",
      "-> Found 91,325 rows.\n",
      "-> Loading 'currencyexchange' into DataFrame...\n",
      "-> Successfully loaded 'currencyexchange'. Shape: (91325, 4)\n",
      "\n",
      "Processing table: 'customer'\n",
      "-> Found 104,990 rows.\n",
      "-> Loading 'customer' into DataFrame...\n",
      "-> Successfully loaded 'customer'. Shape: (104990, 24)\n",
      "\n",
      "Processing table: 'product'\n",
      "-> Found 2,517 rows.\n",
      "-> Loading 'product' into DataFrame...\n",
      "-> Successfully loaded 'product'. Shape: (2517, 14)\n",
      "\n",
      "Processing table: 'sales'\n",
      "-> Found 199,873 rows.\n",
      "-> Loading 'sales' into DataFrame...\n",
      "-> Successfully loaded 'sales'. Shape: (199873, 13)\n",
      "\n",
      "Processing table: 'store'\n",
      "-> Found 74 rows.\n",
      "-> Loading 'store' into DataFrame...\n",
      "-> Successfully loaded 'store'. Shape: (74, 11)\n",
      "\n",
      "Processing table: 'date'\n",
      "-> Found 3,653 rows.\n",
      "-> Loading 'date' into DataFrame...\n",
      "-> Successfully loaded 'date'. Shape: (3653, 17)\n",
      "\n",
      "--- Data Loading Summary ---\n",
      "Successfully loaded DataFrames for:\n",
      "- currencyexchange: (91325, 4)\n",
      "- customer: (104990, 24)\n",
      "- product: (2517, 14)\n",
      "- sales: (199873, 13)\n",
      "- store: (74, 11)\n",
      "- date: (3653, 17)\n",
      "\n",
      "Next Steps: Data cleaning, EDA, and analysis.\n",
      "Consider optimizing DataFrame memory usage with .astype() if needed.\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Database Configuration ---\n",
    "# Store configuration in a dictionary for clarity.\n",
    "# IMPORTANT: Replace placeholder values with your actual credentials.\n",
    "# Consider using environment variables or a config file for production/shared code.\n",
    "DB_CONFIG = {\n",
    "    \"type\": \"postgresql\",\n",
    "    \"driver\": \"psycopg2\",\n",
    "    \"user\": \"postgres\", \n",
    "    \"pass\": \"password\", \n",
    "    \"host\": \"localhost\", \n",
    "    \"port\": \"5432\", \n",
    "    \"name\": \"contoso_100k\" \n",
    "}\n",
    "\n",
    "# --- 2. Database Connection Function ---\n",
    "def create_db_engine(config):\n",
    "    \"\"\"\n",
    "    Creates a SQLAlchemy engine for the database connection.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Dictionary containing database connection parameters.\n",
    "\n",
    "    Returns:\n",
    "        sqlalchemy.engine.Engine or None: The created engine, or None if connection fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the database connection URL\n",
    "        connection_url = (\n",
    "            f\"{config['type']}+{config['driver']}://\"\n",
    "            f\"{config['user']}:{config['pass']}@\"\n",
    "            f\"{config['host']}:{config['port']}/{config['name']}\"\n",
    "        )\n",
    "        engine = create_engine(connection_url)\n",
    "        # Test connection briefly\n",
    "        with engine.connect() as _:\n",
    "            pass # Connection successful if this doesn't raise an error\n",
    "        print(\"Database connection established successfully.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 3. Table Loading Function ---\n",
    "def load_dataframes_from_db(engine, table_names):\n",
    "    \"\"\"\n",
    "    Loads specified tables from the database into a dictionary of pandas DataFrames,\n",
    "    checking row counts beforehand.\n",
    "\n",
    "    Args:\n",
    "        engine (sqlalchemy.engine.Engine): The SQLAlchemy engine to use for connection.\n",
    "        table_names (list): A list of table names to load.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are table names (e.g., 'sales')\n",
    "              and values are the corresponding pandas DataFrames. Returns an empty\n",
    "              dictionary if errors occur during loading.\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "    print(\"\\n--- Loading Tables into DataFrames ---\")\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        for table in table_names:\n",
    "            print(f\"\\nProcessing table: '{table}'\")\n",
    "            try:\n",
    "                # Step A: Check row count (Good practice for documentation and large datasets)\n",
    "                count_query = text(f\"SELECT COUNT(*) FROM {table};\")\n",
    "                count_result = connection.execute(count_query)\n",
    "                row_count = count_result.scalar()\n",
    "                print(f\"-> Found {row_count:,} rows.\") # Format count with comma\n",
    "\n",
    "                # Step B: Load table into DataFrame\n",
    "                print(f\"-> Loading '{table}' into DataFrame...\")\n",
    "                df = pd.read_sql_table(table, connection) # Use the existing connection\n",
    "                dataframes[table] = df # Use table name as key\n",
    "                print(f\"-> Successfully loaded '{table}'. Shape: {df.shape}\")\n",
    "\n",
    "                # Optional Step C: Display memory usage for larger tables if needed\n",
    "                # if table == 'sales' or table == 'customer':\n",
    "                #    print(\"   Memory Usage:\")\n",
    "                #    df.info(memory_usage='deep', verbose=False) # Concise info\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR loading table '{table}': {e}\")\n",
    "                print(f\"Skipping table '{table}'.\")\n",
    "                # Decide if you want to stop entirely or just skip the table\n",
    "                # If critical tables fail, you might want `return {}` here\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "# --- 4. Main Execution ---\n",
    "print(\"--- Contoso Data Loading ---\")\n",
    "\n",
    "# Create the database engine\n",
    "db_engine = create_db_engine(DB_CONFIG)\n",
    "\n",
    "# Proceed only if the connection was successful\n",
    "if db_engine:\n",
    "    # Define the tables we want to load\n",
    "    tables_to_load = [\"currencyexchange\", \"customer\", \"product\", \"sales\", \"store\", \"date\"]\n",
    "\n",
    "    # Load the tables into dataframes\n",
    "    loaded_dfs = load_dataframes_from_db(db_engine, tables_to_load)\n",
    "\n",
    "    if loaded_dfs:\n",
    "        print(\"\\n--- Data Loading Summary ---\")\n",
    "        print(\"Successfully loaded DataFrames for:\")\n",
    "        for name, df in loaded_dfs.items():\n",
    "            print(f\"- {name}: {df.shape}\")\n",
    "\n",
    "        # You can now access your dataframes using the dictionary keys, e.g.:\n",
    "        # sales_df = loaded_dfs['sales']\n",
    "        # customer_df = loaded_dfs['customer']\n",
    "        # product_df = loaded_dfs['product']\n",
    "        # store_df = loaded_dfs['store']\n",
    "        # currency_df = loaded_dfs['currencyexchange']\n",
    "        # date_df = loaded_dfs['date']\n",
    "        # print(\"\\nExample: First 5 rows of 'customer' data:\")\n",
    "        # if 'customer' in loaded_dfs:\n",
    "        #     print(loaded_dfs['customer'].head())\n",
    "\n",
    "        # Reminder about next steps\n",
    "        print(\"\\nNext Steps: Data cleaning, EDA, and analysis.\")\n",
    "        print(\"Consider optimizing DataFrame memory usage with .astype() if needed.\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo DataFrames were loaded due to errors.\")\n",
    "\n",
    "    # Dispose the engine connection pool when completely done\n",
    "    db_engine.dispose()\n",
    "    print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nScript aborted due to database connection failure.\")\n",
    "    sys.exit(1) # Exit with an error code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a90b82",
   "metadata": {},
   "source": [
    "### Create a master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2203e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Setting Indices on Dimension Tables ---\n",
      "Index set for 'product_df' using 'productkey'.\n",
      "Index set for 'customer_df' using 'customerkey'.\n",
      "Index set for 'store_df' using 'storekey'.\n",
      "\n",
      "--- Step 2: Preparing sales_df and Creating Master Analysis DataFrame ---\n",
      "Starting with sales_df (Shape: (199873, 13))\n",
      "Converting date columns...\n",
      "Merged with product_df. Shape: (199873, 26)\n",
      "Merged with customer_df. Shape: (199873, 49)\n",
      "Merged with store_df. Shape: (199873, 59)\n",
      "\n",
      "Verifying final merged DataFrame ('analysis_df'):\n",
      "Final Shape: (199873, 59)\n",
      "Row count matches original sales data.\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199873 entries, 0 to 199872\n",
      "Data columns (total 59 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   orderkey          199873 non-null  int64         \n",
      " 1   linenumber        199873 non-null  int64         \n",
      " 2   orderdate         199873 non-null  datetime64[ns]\n",
      " 3   deliverydate      199873 non-null  datetime64[ns]\n",
      " 4   customerkey       199873 non-null  int64         \n",
      " 5   storekey          199873 non-null  int64         \n",
      " 6   productkey        199873 non-null  int64         \n",
      " 7   quantity          199873 non-null  int64         \n",
      " 8   unitprice         199873 non-null  float64       \n",
      " 9   netprice          199873 non-null  float64       \n",
      " 10  unitcost          199873 non-null  float64       \n",
      " 11  currencycode      199873 non-null  object        \n",
      " 12  exchangerate      199873 non-null  float64       \n",
      " 13  productcode       199873 non-null  int64         \n",
      " 14  productname       199873 non-null  object        \n",
      " 15  manufacturer      199873 non-null  object        \n",
      " 16  brand             199873 non-null  object        \n",
      " 17  color             199873 non-null  object        \n",
      " 18  weightunit        187729 non-null  object        \n",
      " 19  weight            168559 non-null  float64       \n",
      " 20  cost              199873 non-null  float64       \n",
      " 21  price             199873 non-null  float64       \n",
      " 22  categorykey       199873 non-null  int64         \n",
      " 23  categoryname      199873 non-null  object        \n",
      " 24  subcategorykey    199873 non-null  int64         \n",
      " 25  subcategoryname   199873 non-null  object        \n",
      " 26  geoareakey        199873 non-null  int64         \n",
      " 27  startdt           199873 non-null  datetime64[ns]\n",
      " 28  enddt             199873 non-null  datetime64[ns]\n",
      " 29  continent         199873 non-null  object        \n",
      " 30  gender            199873 non-null  object        \n",
      " 31  title             199873 non-null  object        \n",
      " 32  givenname         199873 non-null  object        \n",
      " 33  middleinitial     199873 non-null  object        \n",
      " 34  surname           199873 non-null  object        \n",
      " 35  streetaddress     199873 non-null  object        \n",
      " 36  city              199873 non-null  object        \n",
      " 37  state             199873 non-null  object        \n",
      " 38  statefull         199873 non-null  object        \n",
      " 39  zipcode           199873 non-null  object        \n",
      " 40  country           199873 non-null  object        \n",
      " 41  countryfull       199873 non-null  object        \n",
      " 42  birthday          199873 non-null  datetime64[ns]\n",
      " 43  age               199873 non-null  int64         \n",
      " 44  occupation        199873 non-null  object        \n",
      " 45  company           199709 non-null  object        \n",
      " 46  vehicle           199873 non-null  object        \n",
      " 47  latitude          199873 non-null  float64       \n",
      " 48  longitude         199873 non-null  float64       \n",
      " 49  storecode         199873 non-null  int64         \n",
      " 50  geoareakey_store  199873 non-null  int64         \n",
      " 51  countrycode       199873 non-null  object        \n",
      " 52  countryname       199873 non-null  object        \n",
      " 53  state_store       199873 non-null  object        \n",
      " 54  opendate          199873 non-null  datetime64[ns]\n",
      " 55  closedate         5118 non-null    datetime64[ns]\n",
      " 56  description       199873 non-null  object        \n",
      " 57  squaremeters      121568 non-null  float64       \n",
      " 58  status            3697 non-null    object        \n",
      "dtypes: datetime64[ns](7), float64(10), int64(13), object(29)\n",
      "memory usage: 411.0 MB\n",
      "\n",
      "--- Step 3: Setting DateTimeIndex ---\n",
      "Successfully set 'orderdate' column as DateTimeIndex.\n",
      "Index Type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "Date Range: 2015-01-01 00:00:00 to 2024-04-20 00:00:00\n",
      "\n",
      "Setup complete! 'analysis_df' is ready with 'orderdate' as DateTimeIndex.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Set Indices on Dimension Tables (Product, Customer, Store) ---\n",
    "\n",
    "print(\"--- Step 1: Setting Indices on Dimension Tables ---\")\n",
    "\n",
    "dimension_tables = ['product', 'customer', 'store']\n",
    "key_columns = {'product': 'productkey', 'customer': 'customerkey', 'store': 'storekey'}\n",
    "\n",
    "indices_set = {}\n",
    "\n",
    "try:\n",
    "    for table_key in dimension_tables:\n",
    "        if table_key in loaded_dfs:\n",
    "            df = loaded_dfs[table_key]\n",
    "            key_col = key_columns[table_key]\n",
    "\n",
    "            if key_col in df.columns:\n",
    "                # Check uniqueness\n",
    "                if df[key_col].is_unique:\n",
    "                    df.set_index(key_col, inplace=True)\n",
    "                    print(f\"Index set for '{table_key}_df' using '{key_col}'.\")\n",
    "                    indices_set[table_key] = True\n",
    "                else:\n",
    "                    print(f\"WARNING: '{key_col}' in {table_key}_df is not unique. Index not set.\")\n",
    "                    indices_set[table_key] = False\n",
    "            else:\n",
    "                print(f\"WARNING: Key column '{key_col}' not found in {table_key}_df.\")\n",
    "                indices_set[table_key] = False\n",
    "        else:\n",
    "            print(f\"WARNING: DataFrame '{table_key}' not found in loaded_dfs.\")\n",
    "            indices_set[table_key] = False\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during index setting: {e}\")\n",
    "\n",
    "\n",
    "# --- Step 2: Prepare sales_df (Date Conversions) & Create Master Analysis DataFrame ---\n",
    "\n",
    "print(\"\\n--- Step 2: Preparing sales_df and Creating Master Analysis DataFrame ---\")\n",
    "\n",
    "analysis_df = None # Initialize\n",
    "\n",
    "if 'sales' in loaded_dfs:\n",
    "    # Make a copy to avoid modifying the original loaded DataFrame directly\n",
    "    sales_df = loaded_dfs['sales'].copy()\n",
    "    print(f\"Starting with sales_df (Shape: {sales_df.shape})\")\n",
    "\n",
    "    # Convert date columns to datetime objects\n",
    "    date_cols = ['orderdate', 'deliverydate']\n",
    "    print(\"Converting date columns...\")\n",
    "    for col in date_cols:\n",
    "        if col in sales_df.columns:\n",
    "            sales_df[col] = pd.to_datetime(sales_df[col], errors='coerce')\n",
    "            # Check conversion success\n",
    "            null_dates = sales_df[col].isnull().sum()\n",
    "            if null_dates > 0:\n",
    "                print(f\"WARNING: {null_dates} null values found/created in '{col}' after conversion.\")\n",
    "        else:\n",
    "            print(f\"WARNING: Date column '{col}' not found in sales_df.\")\n",
    "\n",
    "    # --- Perform Merges ---\n",
    "    try:\n",
    "        analysis_df = sales_df # Start with the prepared sales_df\n",
    "\n",
    "        # Merge with Product\n",
    "        prod_key = key_columns['product']\n",
    "        if indices_set.get('product') and prod_key in analysis_df.columns:\n",
    "             analysis_df = pd.merge(\n",
    "                analysis_df, \n",
    "                loaded_dfs['product'],\n",
    "                left_on=prod_key, \n",
    "                right_index=True, \n",
    "                how='left',\n",
    "                suffixes=('', '_prod')\n",
    "            ) # Add suffix if overlapping columns exist\n",
    "             print(f\"Merged with product_df. Shape: {analysis_df.shape}\")\n",
    "        else:\n",
    "             print(f\"Skipping product merge (Index not set or '{prod_key}' missing).\")\n",
    "\n",
    "        # Merge with Customer\n",
    "        cust_key = key_columns['customer']\n",
    "        if indices_set.get('customer') and cust_key in analysis_df.columns:\n",
    "             analysis_df = pd.merge(\n",
    "                analysis_df, \n",
    "                loaded_dfs['customer'],\n",
    "                left_on=cust_key, \n",
    "                right_index=True, \n",
    "                how='left',\n",
    "                suffixes=('', '_cust')\n",
    "            )\n",
    "             print(f\"Merged with customer_df. Shape: {analysis_df.shape}\")\n",
    "        else:\n",
    "             print(f\"Skipping customer merge (Index not set or '{cust_key}' missing).\")\n",
    "\n",
    "        # Merge with Store\n",
    "        store_key = key_columns['store']\n",
    "        if indices_set.get('store') and store_key in analysis_df.columns:\n",
    "             analysis_df = pd.merge(\n",
    "                analysis_df, \n",
    "                loaded_dfs['store'],\n",
    "                left_on=store_key, \n",
    "                right_index=True, \n",
    "                how='left',\n",
    "                suffixes=('', '_store')\n",
    "            )\n",
    "             print(f\"Merged with store_df. Shape: {analysis_df.shape}\")\n",
    "        else:\n",
    "             print(f\"Skipping store merge (Index not set or '{store_key}' missing).\")\n",
    "\n",
    "        print(\"\\nVerifying final merged DataFrame ('analysis_df'):\")\n",
    "        print(f\"Final Shape: {analysis_df.shape}\")\n",
    "        if analysis_df.shape[0] == loaded_dfs['sales'].shape[0]:\n",
    "            print(\"Row count matches original sales data.\")\n",
    "        else:\n",
    "            print(\"WARNING: Row count changed after merges. Check merge keys and types.\")\n",
    "\n",
    "        print(\"\\nDataFrame Info:\")\n",
    "        analysis_df.info(memory_usage='deep')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during merging: {e}\")\n",
    "        analysis_df = None\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: 'sales' DataFrame not found in loaded_dfs.\")\n",
    "\n",
    "\n",
    "# --- Step 3: Set Primary DateTimeIndex ('orderdate') ---\n",
    "\n",
    "print(\"\\n--- Step 3: Setting DateTimeIndex ---\")\n",
    "\n",
    "primary_date_col = 'orderdate' # Choose the main date column for indexing\n",
    "\n",
    "if analysis_df is not None and primary_date_col in analysis_df.columns:\n",
    "    try:\n",
    "        # Ensure the column is datetime type\n",
    "        if pd.api.types.is_datetime64_any_dtype(analysis_df[primary_date_col]):\n",
    "            # Check for NaT values before setting index if critical\n",
    "            nat_count = analysis_df[primary_date_col].isnull().sum()\n",
    "            if nat_count > 0:\n",
    "                 print(f\"WARNING: {nat_count} rows have null values in '{primary_date_col}'. They will have NaT index.\")\n",
    "                 # Optionally, handle these rows first (e.g., drop, fill)\n",
    "                 # analysis_df.dropna(subset=[primary_date_col], inplace=True)\n",
    "\n",
    "            analysis_df.set_index(primary_date_col, inplace=True)\n",
    "            # Sort index for time series analysis\n",
    "            analysis_df.sort_index(inplace=True)\n",
    "            print(f\"Successfully set '{primary_date_col}' column as DateTimeIndex.\")\n",
    "            print(f\"Index Type: {type(analysis_df.index)}\")\n",
    "            print(f\"Date Range: {analysis_df.index.min()} to {analysis_df.index.max()}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Column '{primary_date_col}' is not datetime type. Cannot set DateTimeIndex.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred setting DateTimeIndex: {e}\")\n",
    "\n",
    "elif analysis_df is not None:\n",
    "    print(f\"WARNING: Column '{primary_date_col}' not found in analysis_df. Cannot set DateTimeIndex.\")\n",
    "else:\n",
    "    print(\"Skipping DateTimeIndex setting as analysis_df was not created.\")\n",
    "\n",
    "# --- Ready for Analysis ---\n",
    "# Check if analysis_df exists and if its index is a DateTimeIndex type\n",
    "if analysis_df is not None and ptypes.is_datetime64_any_dtype(analysis_df.index):\n",
    "    print(f\"\\nSetup complete! 'analysis_df' is ready with '{primary_date_col}' as DateTimeIndex.\")\n",
    "    # Optional: view first few rows\n",
    "    # print(\"\\nSample of analysis_df:\")\n",
    "    # print(analysis_df.head())\n",
    "    # Optional: view columns to check merges and suffixes\n",
    "    # print(\"\\nColumns in analysis_df:\")\n",
    "    # print(analysis_df.columns)\n",
    "else:\n",
    "    # Provide more specific feedback if possible\n",
    "    if analysis_df is None:\n",
    "         print(\"\\nSetup incomplete: 'analysis_df' was not created. Please review previous errors.\")\n",
    "    elif not ptypes.is_datetime64_any_dtype(analysis_df.index):\n",
    "         print(f\"\\nSetup incomplete: The index of 'analysis_df' is not a DateTimeIndex (Type: {type(analysis_df.index)}). Check Step 3.\")\n",
    "    else:\n",
    "         print(\"\\nSetup incomplete. Please review warnings/errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21a31e",
   "metadata": {},
   "source": [
    "### Calculate line totals & currency conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd84122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderkey</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>unitcost</th>\n",
       "      <th>netprice</th>\n",
       "      <th>quantity</th>\n",
       "      <th>currencycode</th>\n",
       "      <th>exchangerate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orderdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>973004</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0658</td>\n",
       "      <td>10.742</td>\n",
       "      <td>21.0658</td>\n",
       "      <td>4</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-18</th>\n",
       "      <td>3091005</td>\n",
       "      <td>1</td>\n",
       "      <td>42.9900</td>\n",
       "      <td>14.240</td>\n",
       "      <td>38.2611</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.91191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-03</th>\n",
       "      <td>3076045</td>\n",
       "      <td>2</td>\n",
       "      <td>256.0000</td>\n",
       "      <td>117.730</td>\n",
       "      <td>256.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.92911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-02</th>\n",
       "      <td>1522032</td>\n",
       "      <td>3</td>\n",
       "      <td>492.8000</td>\n",
       "      <td>226.624</td>\n",
       "      <td>438.5920</td>\n",
       "      <td>3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.87850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-26</th>\n",
       "      <td>635004</td>\n",
       "      <td>4</td>\n",
       "      <td>224.9925</td>\n",
       "      <td>114.705</td>\n",
       "      <td>197.9934</td>\n",
       "      <td>4</td>\n",
       "      <td>CAD</td>\n",
       "      <td>1.31637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            orderkey  quantity  unitprice  unitcost  netprice  quantity  \\\n",
       "orderdate                                                                 \n",
       "2017-08-30    973004         4    21.0658    10.742   21.0658         4   \n",
       "2023-06-18   3091005         1    42.9900    14.240   38.2611         1   \n",
       "2023-06-03   3076045         2   256.0000   117.730  256.0000         2   \n",
       "2019-03-02   1522032         3   492.8000   226.624  438.5920         3   \n",
       "2016-09-26    635004         4   224.9925   114.705  197.9934         4   \n",
       "\n",
       "           currencycode  exchangerate  \n",
       "orderdate                              \n",
       "2017-08-30          USD       1.00000  \n",
       "2023-06-18          EUR       0.91191  \n",
       "2023-06-03          EUR       0.92911  \n",
       "2019-03-02          EUR       0.87850  \n",
       "2016-09-26          CAD       1.31637  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df[['orderkey', 'quantity', 'unitprice', 'unitcost', 'netprice', 'quantity', 'currencycode', 'exchangerate']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7643dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recalculating Totals and Converting Currency ---\n",
      "Calculating line totals (Revenue, Cost, Profit)...\n",
      "Line totals calculated.\n",
      "Converting monetary values to USD...\n",
      "Currency conversion to USD complete.\n",
      "\n",
      "--- Defining Core Metrics (USD) ---\n",
      "Using 'revenue_usd' for Revenue analysis.\n",
      "Using 'cost_usd' for Cost analysis.\n",
      "Using 'profit_usd' for Profit analysis.\n",
      "Using 'quantity' for Quantity analysis.\n",
      "\n",
      "Basic check on 'revenue_usd':\n",
      "Null USD Revenue values: 0\n",
      "count    199873.000000\n",
      "mean       1032.021066\n",
      "std        1986.128568\n",
      "min           0.601549\n",
      "25%         105.328080\n",
      "50%         395.964000\n",
      "75%        1121.147355\n",
      "max       57749.932598\n",
      "Name: revenue_usd, dtype: float64\n",
      "Number of non-positive USD revenue entries: 0\n",
      "\n",
      "Basic check on 'quantity':\n",
      "count    199873.000000\n",
      "mean          3.143846\n",
      "std           2.252006\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           2.000000\n",
      "75%           4.000000\n",
      "max          10.000000\n",
      "Name: quantity, dtype: float64\n",
      "Number of non-positive quantity entries: 0\n",
      "\n",
      "Index Check:\n",
      "Index Type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "Date Range: 2015-01-01 00:00:00 to 2024-04-20 00:00:00\n",
      "Inferred Index Frequency: None\n",
      "\n",
      "Plotting style set.\n",
      "\n",
      "--- Ready for Analysis ---\n"
     ]
    }
   ],
   "source": [
    "# --- Pre-Analysis: Calculate Line Totals & Convert Currency ---\n",
    "\n",
    "print(\"--- Recalculating Totals and Converting Currency ---\")\n",
    "\n",
    "# Make a copy to ensure we don't modify the original analysis_df accidentally\n",
    "# if doing interactive work. If this is the main script flow, you can work directly.\n",
    "df = analysis_df.copy()\n",
    "\n",
    "# --- 1. Calculate Line Totals (in original currency) ---\n",
    "try:\n",
    "    print(\"Calculating line totals (Revenue, Cost, Profit)...\")\n",
    "    # Revenue = Quantity * Net Price per unit\n",
    "    df['line_revenue'] = df['quantity'] * df['netprice']\n",
    "\n",
    "    # Cost = Quantity * Unit Cost per unit\n",
    "    df['line_cost'] = df['quantity'] * df['unitcost']\n",
    "\n",
    "    # Profit = Line Revenue - Line Cost\n",
    "    df['line_profit'] = df['line_revenue'] - df['line_cost']\n",
    "\n",
    "    print(\"Line totals calculated.\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"ERROR: Missing column for calculation: {e}\")\n",
    "    # Handle error - maybe stop processing\n",
    "    df = None # Indicate failure\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during line total calculation: {e}\")\n",
    "    df = None\n",
    "\n",
    "# --- 2. Currency Conversion to USD ---\n",
    "if df is not None:\n",
    "    try:\n",
    "        print(\"Converting monetary values to USD...\")\n",
    "        required_cols = ['line_revenue', 'line_cost', 'line_profit', 'currencycode', 'exchangerate']\n",
    "        if all(col in df.columns for col in required_cols):\n",
    "\n",
    "            # Handle potential division by zero or null exchange rates\n",
    "            # Replace 0 or NaN exchange rates with NaN to avoid errors and identify issues\n",
    "            df['exchangerate'] = df['exchangerate'].replace(0, np.nan)\n",
    "\n",
    "            # Convert to USD: Divide local currency value by the exchange rate\n",
    "            # If currency is already USD, the rate should be 1, but division is safe.\n",
    "            df['revenue_usd'] = df['line_revenue'] / df['exchangerate']\n",
    "            df['cost_usd'] = df['line_cost'] / df['exchangerate']\n",
    "            df['profit_usd'] = df['line_profit'] / df['exchangerate']\n",
    "\n",
    "            print(\"Currency conversion to USD complete.\")\n",
    "\n",
    "            # Optional: Verify for a non-USD currency\n",
    "            # print(\"\\nSample conversion check (e.g., first EUR entry):\")\n",
    "            # print(df[df['currencycode'] == 'EUR'][['line_revenue', 'exchangerate', 'revenue_usd']].head(1))\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING: Missing columns required for currency conversion.\")\n",
    "            # Decide how to handle this - maybe stop, or proceed without USD values\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during currency conversion: {e}\")\n",
    "        # Potentially set USD columns to NaN or stop processing\n",
    "        df = None\n",
    "\n",
    "\n",
    "# --- 3. Define Core Metrics (Now using USD values) ---\n",
    "if df is not None:\n",
    "    print(\"\\n--- Defining Core Metrics (USD) ---\")\n",
    "    revenue_col = 'revenue_usd'\n",
    "    cost_col = 'cost_usd'\n",
    "    profit_col = 'profit_usd'\n",
    "    quantity_col = 'quantity' # Remains the same\n",
    "\n",
    "    print(f\"Using '{revenue_col}' for Revenue analysis.\")\n",
    "    print(f\"Using '{cost_col}' for Cost analysis.\")\n",
    "    print(f\"Using '{profit_col}' for Profit analysis.\")\n",
    "    print(f\"Using '{quantity_col}' for Quantity analysis.\")\n",
    "\n",
    "\n",
    "    # --- 4. Sanity Check Key USD Columns & Index ---\n",
    "    print(f\"\\nBasic check on '{revenue_col}':\")\n",
    "    # Check for NaNs introduced by conversion issues\n",
    "    print(f\"Null USD Revenue values: {df[revenue_col].isnull().sum()}\")\n",
    "    print(df[revenue_col].describe())\n",
    "    print(f\"Number of non-positive USD revenue entries: {(df[revenue_col] <= 0).sum()}\") # May include nulls\n",
    "\n",
    "    print(f\"\\nBasic check on '{quantity_col}':\") # Quantity check remains same\n",
    "    print(df[quantity_col].describe())\n",
    "    print(f\"Number of non-positive quantity entries: {(df[quantity_col] <= 0).sum()}\")\n",
    "\n",
    "\n",
    "    # Check DateTimeIndex (using the processed dataframe)\n",
    "    print(\"\\nIndex Check:\")\n",
    "    print(f\"Index Type: {type(df.index)}\")\n",
    "    if df is not None and ptypes.is_datetime64_any_dtype(df.index):\n",
    "        print(f\"Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "        inferred_freq = pd.infer_freq(df.index)\n",
    "        print(f\"Inferred Index Frequency: {inferred_freq}\") # Still likely None\n",
    "    else:\n",
    "        print(\"WARNING: Index is not a DateTimeIndex!\")\n",
    "\n",
    "    # --- Set Plotting Style ---\n",
    "    # sns.set_theme(style=\"whitegrid\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    print(\"\\nPlotting style set.\")\n",
    "\n",
    "    print(\"\\n--- Ready for Analysis ---\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nProcessing failed. Cannot proceed to analysis.\")\n",
    "\n",
    "\n",
    "# IMPORTANT: Use 'df' for subsequent analysis cells!\n",
    "\n",
    "# Save master df to a parquet file\n",
    "df.to_parquet('contoso_100k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2c8a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderkey</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>unitcost</th>\n",
       "      <th>netprice</th>\n",
       "      <th>quantity</th>\n",
       "      <th>currencycode</th>\n",
       "      <th>exchangerate</th>\n",
       "      <th>line_revenue</th>\n",
       "      <th>line_cost</th>\n",
       "      <th>line_profit</th>\n",
       "      <th>revenue_usd</th>\n",
       "      <th>cost_usd</th>\n",
       "      <th>profit_usd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orderdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-05</th>\n",
       "      <td>3200023</td>\n",
       "      <td>2</td>\n",
       "      <td>22.890</td>\n",
       "      <td>7.580</td>\n",
       "      <td>19.91430</td>\n",
       "      <td>2</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>39.82860</td>\n",
       "      <td>15.160</td>\n",
       "      <td>24.66860</td>\n",
       "      <td>39.828600</td>\n",
       "      <td>15.160000</td>\n",
       "      <td>24.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-23</th>\n",
       "      <td>2670011</td>\n",
       "      <td>3</td>\n",
       "      <td>107.991</td>\n",
       "      <td>55.053</td>\n",
       "      <td>92.87226</td>\n",
       "      <td>3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.92447</td>\n",
       "      <td>278.61678</td>\n",
       "      <td>165.159</td>\n",
       "      <td>113.45778</td>\n",
       "      <td>301.380012</td>\n",
       "      <td>178.652633</td>\n",
       "      <td>122.727379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>2562015</td>\n",
       "      <td>1</td>\n",
       "      <td>329.925</td>\n",
       "      <td>168.210</td>\n",
       "      <td>290.33400</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>290.33400</td>\n",
       "      <td>168.210</td>\n",
       "      <td>122.12400</td>\n",
       "      <td>290.334000</td>\n",
       "      <td>168.210000</td>\n",
       "      <td>122.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-06</th>\n",
       "      <td>3201026</td>\n",
       "      <td>2</td>\n",
       "      <td>290.000</td>\n",
       "      <td>133.360</td>\n",
       "      <td>258.10000</td>\n",
       "      <td>2</td>\n",
       "      <td>GBP</td>\n",
       "      <td>0.81899</td>\n",
       "      <td>516.20000</td>\n",
       "      <td>266.720</td>\n",
       "      <td>249.48000</td>\n",
       "      <td>630.288526</td>\n",
       "      <td>325.669422</td>\n",
       "      <td>304.619104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>2141003</td>\n",
       "      <td>3</td>\n",
       "      <td>50.400</td>\n",
       "      <td>25.695</td>\n",
       "      <td>50.40000</td>\n",
       "      <td>3</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>151.20000</td>\n",
       "      <td>77.085</td>\n",
       "      <td>74.11500</td>\n",
       "      <td>151.200000</td>\n",
       "      <td>77.085000</td>\n",
       "      <td>74.115000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            orderkey  quantity  unitprice  unitcost   netprice  quantity  \\\n",
       "orderdate                                                                  \n",
       "2023-10-05   3200023         2     22.890     7.580   19.91430         2   \n",
       "2022-04-23   2670011         3    107.991    55.053   92.87226         3   \n",
       "2022-01-05   2562015         1    329.925   168.210  290.33400         1   \n",
       "2023-10-06   3201026         2    290.000   133.360  258.10000         2   \n",
       "2020-11-10   2141003         3     50.400    25.695   50.40000         3   \n",
       "\n",
       "           currencycode  exchangerate  line_revenue  line_cost  line_profit  \\\n",
       "orderdate                                                                     \n",
       "2023-10-05          USD       1.00000      39.82860     15.160     24.66860   \n",
       "2022-04-23          EUR       0.92447     278.61678    165.159    113.45778   \n",
       "2022-01-05          USD       1.00000     290.33400    168.210    122.12400   \n",
       "2023-10-06          GBP       0.81899     516.20000    266.720    249.48000   \n",
       "2020-11-10          USD       1.00000     151.20000     77.085     74.11500   \n",
       "\n",
       "            revenue_usd    cost_usd  profit_usd  \n",
       "orderdate                                        \n",
       "2023-10-05    39.828600   15.160000   24.668600  \n",
       "2022-04-23   301.380012  178.652633  122.727379  \n",
       "2022-01-05   290.334000  168.210000  122.124000  \n",
       "2023-10-06   630.288526  325.669422  304.619104  \n",
       "2020-11-10   151.200000   77.085000   74.115000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['orderkey', 'quantity', 'unitprice', 'unitcost', 'netprice', 'quantity', 'currencycode', 'exchangerate', 'line_revenue', 'line_cost', 'line_profit', 'revenue_usd', 'cost_usd', 'profit_usd']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591d484",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0d77b",
   "metadata": {},
   "source": [
    "Theme 1: Sales Performance Over Time (Focus: Time Series Analysis, Aggregation, Visualization)\n",
    "\n",
    "Q1.1: How did key sales metrics (Total Revenue, Units Sold) trend monthly?\n",
    "\n",
    "Goal: Understand the overall sales trajectory.\n",
    "Techniques:\n",
    "Merge sales with a date dimension table if necessary (or parse DateKey/SalesDate).\n",
    "Convert date columns to datetime objects (pd.to_datetime).\n",
    "Set date as index (.set_index()).\n",
    "Resample data by month (.resample('M')).\n",
    "Aggregate (.sum(), .count()).\n",
    "Visualize trends using line plots (matplotlib or seaborn).\n",
    "Skills Showcased: Time series handling, aggregation, basic plotting.\n",
    "\n",
    "Q1.2: Is there evidence of seasonality in sales? Which months consistently perform best/worst?\n",
    "\n",
    "Goal: Identify recurring patterns within the year.\n",
    "Techniques:\n",
    "Group aggregated monthly data by month number (.groupby(df.index.month)).\n",
    "Calculate average monthly performance (.mean()).\n",
    "Visualize using bar charts or box plots per month (sns.barplot, sns.boxplot).\n",
    "(Advanced) Use time series decomposition (statsmodels.tsa.seasonal_decompose) to separate trend, seasonality, and residuals.\n",
    "Skills Showcased: Advanced time series analysis, grouping, statistical visualization, (optional: using stats libraries).\n",
    "Theme 2: Product Insights (Focus: Merging, Profit Calculation, Ranking, Distribution Analysis)\n",
    "\n",
    "Q2.1: Which product categories and sub-categories are the most profitable? (Requires product cost info).\n",
    "\n",
    "Goal: Identify high-margin areas of the business.\n",
    "Techniques:\n",
    "Merge sales with product (pd.merge on ProductKey).\n",
    "Calculate profit per transaction (e.g., (UnitPrice - ProductCost) * Quantity or SalesAmount - (ProductCost * Quantity)). Ensure costs and sales amounts are comparable.\n",
    "Group by Category, Subcategory (.groupby()).\n",
    "Aggregate total profit (.sum()).\n",
    "Visualize using sorted bar charts.\n",
    "Skills Showcased: Data merging, feature engineering (profit calculation), multi-level grouping, aggregation, comparative visualization.\n",
    "\n",
    "Q2.2: What does the distribution of sales look like across different price points?\n",
    "\n",
    "Goal: Understand sales volume relative to product price.\n",
    "Techniques:\n",
    "Use the merged sales and product DataFrame.\n",
    "Create price bins/ranges (pd.cut) if desired.\n",
    "Analyze the distribution of UnitPrice or SalesAmount using histograms or KDE plots (sns.histplot, sns.kdeplot).\n",
    "Use scatter plots (sns.scatterplot) to view UnitPrice vs. Quantity sold per transaction.\n",
    "Skills Showcased: Distribution analysis, visualization (histograms, scatter plots), data binning.\n",
    "Theme 3: Customer Analysis & Segmentation (Focus: Merging, Feature Engineering, Segmentation Techniques, Statistical Comparison)\n",
    "\n",
    "Q3.1: What are the demographics (e.g., age group, gender) of our customers and how do they relate to total spending? (Requires customer details like BirthDate, Gender).\n",
    "\n",
    "Goal: Understand who the customers are and their value.\n",
    "Techniques:\n",
    "Merge sales with customer (pd.merge on CustomerKey).\n",
    "Feature Engineering: Calculate age from BirthDate (using current date pd.Timestamp.now() or a fixed date). Create age groups (pd.cut).\n",
    "Group by demographic features (.groupby(['AgeGroup', 'Gender'])).\n",
    "Aggregate total SalesAmount (.sum()) and average SalesAmount (.mean()).\n",
    "Visualize using bar charts, potentially grouped or stacked.\n",
    "Skills Showcased: Merging, feature engineering (date calculation, binning), multi-level grouping, comparative visualization.\n",
    "\n",
    "Q3.2: Can we apply RFM (Recency, Frequency, Monetary) analysis to segment customers?\n",
    "\n",
    "Goal: Create actionable customer segments based on purchase history.\n",
    "Techniques:\n",
    "Requires CustomerKey, SalesDate, SalesAmount.\n",
    "Calculate Recency (days since last purchase), Frequency (total number of transactions), Monetary (total spend) per customer (.groupby('CustomerKey').agg(...)).\n",
    "Create RFM scores, often using quantiles (pd.qcut) to create bins (e.g., 1-5 scale).\n",
    "Combine scores to create RFM segments.\n",
    "Analyze segment characteristics (size, average R/F/M values).\n",
    "Skills Showcased: Advanced aggregation, date difference calculation, quantile-based binning (pd.qcut), customer segmentation logic.\n",
    "\n",
    "Q3.3 (Optional - Hypothesis Test): Is there a statistically significant difference in the average transaction value between male and female customers?\n",
    "\n",
    "Goal: Apply statistical rigor to an observation.\n",
    "Techniques:\n",
    "Use the merged sales and customer DataFrame.\n",
    "Filter data for male and female customers.\n",
    "Perform an independent samples t-test (scipy.stats.ttest_ind) on the SalesAmount for the two groups.\n",
    "Interpret the p-value.\n",
    "Skills Showcased: Basic hypothesis testing (scipy), data filtering, statistical interpretation.\n",
    "Theme 4: Store & Geographic Performance (Focus: Merging, Geospatial Ideas - simple, Comparison Visualization)\n",
    "\n",
    "Q4.1: How do sales compare across different store locations (e.g., cities)?\n",
    "Goal: Identify top-performing regions.\n",
    "Techniques:\n",
    "Merge sales with store (pd.merge on StoreKey).\n",
    "Group by store attribute like City or Region (.groupby()).\n",
    "Aggregate total SalesAmount (.sum()).\n",
    "Visualize using sorted bar charts.\n",
    "(Optional) If lat/lon available, could do a simple scatter plot on a map background (requires extra libraries like contextily maybe).\n",
    "Skills Showcased: Merging, grouping, aggregation, visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
